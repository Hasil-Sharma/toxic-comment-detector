{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"Data/train.csv.zip\"\n",
    "TEST_DATA_PATH = \"Data/test.csv.zip\"\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "comment_col = 'comment_text'\n",
    "train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)\n",
    "COMMENT = 'comment_text'\n",
    "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_pipeline = Pipeline([\n",
    "    ('vect', FeatureUnion([\n",
    "        ('word_vect', TfidfVectorizer()),\n",
    "        ('char_vect', TfidfVectorizer())\n",
    "    ])),\n",
    "    ('selection', SelectFromModel(LogisticRegression(solver = 'sag'))),\n",
    "    ('clf', XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('word_vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'vect__word_vect__sublinear_tf': True,\n",
    "    'vect__word_vect__strip_accents': 'unicode',\n",
    "    'vect__word_vect__analyzer': 'word',\n",
    "    'vect__word_vect__token_pattern': r'\\w{1,}',\n",
    "    'vect__word_vect__max_features': 50000,\n",
    "    'vect__word_vect__ngram_range': (1, 2),\n",
    "    'vect__char_vect__sublinear_tf': True,\n",
    "    'vect__char_vect__strip_accents': 'unicode',\n",
    "    'vect__char_vect__analyzer': 'char',\n",
    "    'vect__char_vect__max_features': 50000,\n",
    "    'vect__char_vect__ngram_range': (2, 6),\n",
    "    'selection__threshold': 0.2,\n",
    "    'clf__learning_rate': 0.2\n",
    "}\n",
    "xgboost_pipeline.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'severe_toxic'\n",
    "print ('Running for ' + label)\n",
    "cv[label] = cross_validate(xgboost_pipeline, train[comment_col], train[label], \n",
    "                           cv = 5, n_jobs = 3, verbose = 10, scoring = ('accuracy', 'roc_auc', 'neg_log_loss'))\n",
    "print (cv[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
