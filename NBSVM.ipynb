{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating baseline for the project using NBSVM (Naive Bayes - Support Vector Machine)\n",
    "\n",
    "NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic ClassiÔ¨Åcation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "- Dataset is multiclass **not** only multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T09:24:38.010293Z",
     "start_time": "2018-04-03T09:24:37.994220Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"downloads/train.csv.zip\"\n",
    "TEST_DATA_PATH = \"downloads/test.csv.zip\"\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "comment_col = 'comment_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:00:25.179319Z",
     "start_time": "2018-04-03T10:00:25.172707Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils.validation import check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T09:24:41.932407Z",
     "start_time": "2018-04-03T09:24:40.044556Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:00:50.413546Z",
     "start_time": "2018-04-03T10:00:50.403776Z"
    }
   },
   "outputs": [],
   "source": [
    "class NbSVMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, modelType = 'lg', **kwargs):\n",
    "        self.modelType = modelType\n",
    "        self.modelArgs = kwargs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        X, y = check_X_y(X, y, accept_sparse=True, multi_output=True)\n",
    "        \n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        self._clf = []\n",
    "        self._r = []\n",
    "        \n",
    "        def cr(X, y, y_i):\n",
    "            p = X[y == y_i].sum(axis = 0)\n",
    "            return (1 + p)/ ((y == y_i).sum() + 1)\n",
    "        \n",
    "        for i in self.classes_:\n",
    "            print('Fitting Model for: ', label_cols[i])\n",
    "            y_i = y[:, i]\n",
    "            log_count_ratio = np.log(cr(X, 1,y_i) / cr(X, 0, y_i))\n",
    "            X_enhanced = X.multiply(log_count_ratio)\n",
    "            \n",
    "            if self.modelType == 'lg':\n",
    "                model = LogisticRegression(**self.modelArgs)\n",
    "            elif self.modelType == 'svm':\n",
    "                model = SGDClassifier(**self.modelArgs)\n",
    "                \n",
    "            self._clf.append(model.fit(X_enhanced, y_i))\n",
    "            self._r.append(log_count_ratio)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        predict = np.zeros((X.shape[0], len(self.classes_)))\n",
    "        for i in range(predict.shape[1]):\n",
    "            predict[:, i] = self._clf[i].predict(X.multiply(self._r[i]))\n",
    "        return predict\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.modelType == 'svm':\n",
    "            print('No Probabilistic Interpretation for SVM')\n",
    "            return None\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        predict_proba = np.zeros((X.shape[0], len(self.classes_)))\n",
    "        for i in range(predict.shape[1]):\n",
    "            predict_proba[:, i] = self._clf[i].predict_proba(X.multiply(self._r[i]))\n",
    "        return predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:00:56.221472Z",
     "start_time": "2018-04-03T10:00:56.208666Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1,2), \n",
    "                      min_df = 3, \n",
    "                      max_df = 0.9, \n",
    "                      strip_accents = 'unicode', use_idf=1,\n",
    "                      smooth_idf=1, sublinear_tf=1)),\n",
    "    ('clf', NbSVMClassifier(modelType = 'svm', loss = 'hinge', class_weight = 'balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T10:02:05.632089Z",
     "start_time": "2018-04-03T10:00:56.956668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model for:  toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasil/.conda/envs/ml-env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model for:  toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasil/.conda/envs/ml-env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model for:  severe_toxic\n",
      "Fitting Model for:  severe_toxic\n",
      "Fitting Model for:  obscene\n",
      "Fitting Model for:  obscene\n",
      "Fitting Model for:  threat\n",
      "Fitting Model for:  threat\n",
      "Fitting Model for:  insult\n",
      "Fitting Model for:  insult\n",
      "Fitting Model for:  identity_hate\n",
      "Fitting Model for:  identity_hate\n",
      "Fitting Model for:  toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hasil/.conda/envs/ml-env/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model for:  severe_toxic\n",
      "Fitting Model for:  obscene\n",
      "Fitting Model for:  threat\n",
      "Fitting Model for:  insult\n",
      "Fitting Model for:  identity_hate\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(pipeline, train[comment_col], train[label_cols], \n",
    "                           n_jobs = 2, return_train_score = False,\n",
    "                           scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-03T09:48:37.478563Z",
     "start_time": "2018-04-03T09:48:37.461446Z"
    }
   },
   "source": [
    "CV Result with Linear Regression using NB features\n",
    "``` python\n",
    "{'fit_time': array([79.08852482, 79.20061374, 42.78198028]),\n",
    " 'score_time': array([6.6369772 , 6.62154627, 5.88802028]),\n",
    " 'test_score': array([0.92122728, 0.92169581, 0.92276744])}\n",
    " ```\n",
    " \n",
    " CV Result with Linear SVM using NB features\n",
    " ```python\n",
    "{'fit_time': array([30.04560089, 30.4099865 , 24.19594097]),\n",
    " 'score_time': array([7.33976412, 7.11350369, 6.19125676]),\n",
    " 'test_score': array([0.91893365, 0.92066178, 0.9214326 ])}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
